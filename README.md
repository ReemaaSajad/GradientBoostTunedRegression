# ğŸ¥ Insurance Charges Prediction using Gradient Boosting Regression

## ğŸ” Overview

This project aims to **predict individual medical insurance charges** using a variety of regression techniques, with a particular focus on **Gradient Boosting**. By incorporating demographic and lifestyle data (age, sex, BMI, number of children, smoking status, and region), the model provides estimates to guide cost expectations and inform healthcare planning.

## âœ¨ Key Features

- ğŸ¤– **Comprehensive Model Comparison**: Evaluates 12 different regression models (e.g., Linear, Lasso, XGBoost, etc.)  
- ğŸ—ï¸ **Robust Data Preprocessing**: Combines numeric scaling, one-hot encoding, and pipeline-based transformations  
- ğŸ”¬ **In-depth Exploratory Data Analysis (EDA)**: Charts, plots, and statistical summaries to identify critical factors  
- ğŸ”§ **Hyperparameter Tuning**: Reduces overfitting and optimizes Gradient Boosting Regressor performance

## ğŸ“¦ Dataset

- **Source**: `insurance.csv`  
- **Attributes**:  
  - `age` â€” Age of the individual  
  - `sex` â€” Biological sex (`male`, `female`)  
  - `bmi` â€” Body Mass Index  
  - `children` â€” Number of dependents covered by insurance  
  - `smoker` â€” Smoking status (`yes`, `no`)  
  - `region` â€” Residential region (`northeast`, `northwest`, `southeast`, `southwest`)  
  - `charges` â€” Annual medical costs (target variable)

## ğŸ› ï¸ Methodology

### ğŸ“Š Exploratory Data Analysis

- **Descriptive Statistics**: Basic counts, means, and missing values check  
- **Visualization**:
  - Bar charts to explore region counts and total charges  
  - Box plots examining sex, smoker, region vs. charges  
  - Scatter plots revealing age vs. charges trends

### ğŸ—ï¸ Model Development

1. **Data Preprocessing**  
   - Numeric features: **MinMax Scaling** for `age`, `bmi`, and `children`  
   - Categorical features: **One-Hot Encoding** for `sex`, `smoker`, and `region`  
   - Target (`charges`): Also scaled for consistent error measurement  

2. **Multiple Regression Models**  
   - **12 Models** tested (Linear, Ridge, Lasso, Elastic Net, SGD, RandomForest, DecisionTree, **GradientBoosting**, AdaBoost, KNN, SVM, XGBoost)  
   - **Train/Test Split** at an 80/20 ratio

3. **Evaluation Metrics**  
   - ğŸ… **RMSE** (Root Mean Squared Error)  
   - ğŸ… **MSE** (Mean Squared Error)  
   - ğŸ… **MAE** (Mean Absolute Error)  
   - ğŸ… **RÂ²** (Coefficient of Determination)

## ğŸ“ˆ Performance

- ğŸ† **Gradient Boosting Regressor** achieved the best results before tuning  
- ğŸ”§ **Hyperparameter Tuning** for `max_depth`, `n_estimators`, `learning_rate`, `subsample` significantly reduced overfitting  
- ğŸ¯ **Tuned RMSE** on test data is approximately **0.069** (with scaled target), indicating high accuracy

## ğŸ’¡ Key Contributions

- ğŸ¤ **Holistic Approach**: End-to-end solution from EDA through deployment-ready model pipelines  
- ğŸ“Š **Insights into Health Factors**: Highlights how smoking, BMI, and age critically impact insurance charges  
- ğŸš€ **Efficient Pipelines**: Demonstrates a robust scikit-learn workflow for data preprocessing and model training

## ğŸ”¬ Limitations and Future Work

- ğŸ“Š **Data Size**: The dataset is relatively small, which may limit generalization  
- ğŸ·ï¸ **Feature Engineering**: Additional non-linear transformations or domain-specific features could improve performance  
- ğŸŒ **Real-World Application**: Further validation required with larger, more diverse datasets

## ğŸ“š References

1. **scikit-learn** â€“ [https://scikit-learn.org](https://scikit-learn.org)  
2. **XGBoost Documentation** â€“ [https://xgboost.readthedocs.io](https://xgboost.readthedocs.io)

## ğŸ™ Acknowledgements

A heartfelt thank you to the **open-source community** for the powerful libraries (NumPy, pandas, Matplotlib, scikit-learn, XGBoost) and to researchers who continually advance the field of machine learning. This project stands on the shoulders of these collective contributions.
